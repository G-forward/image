# 多层感知机&激活函数

## **XOR问题（Minsky & Papert，1969）**

感知机不能拟合XOR函数，它只能产生线性分割面



```html
<div style="display: flex; justify-content: space-around;">
    <img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926161633811.png" alt="XOR二维图像" style="width: 45%;">
    <img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926161653479.png" alt="XOR表格" style="width: 45%;">
</div>
```

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926161633811.png" alt="image-20250926161633811" style="zoom: 80%;" />![image-20250926161653479](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926161653479.png)

![image-20250926162516530](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926162516530.png)



## 1、**sigmoid激活函数**

![image-20250926165608101](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926165608101.png)

![image-20250926165725946](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926165725946.png)



## 2、Tanh函数



![image-20250926165909413](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926165909413.png)

![image-20250926165938074](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926165938074.png)



## 3、ReLU激活函数

![image-20250926170333587](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926170333587.png)

![image-20250926170351247](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250926170351247.png)

**其优点为：**输入为正数时，没有梯度饱和的情况，而且与前两个函数相比，该函数计算速度很快。

**其缺点也比较明显**：它是输出为0或正数，不是以0为中心的函数，就会出现和sigmoid 函数同样的问题；而且当输入为负数时，梯度变成了0，这个问题也称为Dead ReLU问题，在神经网络正向传播中该问题没有任何影响，但是在反向传播修正参数时，如果输入是负数，那么梯度为0，也就无法修正参数了。



```python
def relu(x):
    a = torch.zeros_like(x)
    return torch.max(x,a)

def net(x):
    x = x.reshape((-1, num_inputs))
    H = relu(x @ W1 + b1)
    return (H @ W2 + b2)
```

***注：`@` 符号是矩阵乘法（也称为矩阵点积）的运算符***



## 总结

- 多层感知机使用隐藏层和激活函数来得到非线性模型
- 常用激活函数是Sigmoid，Tanh，ReLU
- 使用Softmax来处理多分类问题
- 超参数为隐藏层，和各个隐藏层大小

